{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import read_config_file\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from utils import read_config_file, process_string, create_csv_file\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import string\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['We are good',\n",
    "        'We are becoming better',\n",
    "        'We will be great']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config files...\n",
      "Reading inverted index file...\n",
      "Inverted index dimensions: (8,3).\n",
      "Computing terms-documents matrix from inverted index...\n",
      "Creating terms-documents matrix file...\n"
     ]
    }
   ],
   "source": [
    "config_file = \"../config/index.cfg\"\n",
    "\n",
    "def compute_term_document_matrix(inverted_index_df, records_num):\n",
    "  terms_frequencies = []\n",
    "\n",
    "  for record_num in records_num:\n",
    "    terms_frequencies.append(inverted_index_df[\"RecordNum\"].str.count(record_num))\n",
    "\n",
    "  terms_frequencies = np.array(terms_frequencies).T\n",
    "\n",
    "  number_of_documents = terms_frequencies.shape[-1]\n",
    "  terms_occurence_on_documents = np.sum(np.where(terms_frequencies > 0, 1, 0), axis=1)\n",
    "  terms_idf = (np.log((1 + number_of_documents)/(1 + terms_occurence_on_documents)) + 1).reshape((terms_occurence_on_documents.shape[0], 1))\n",
    "\n",
    "  term_document_matrix = terms_frequencies * terms_idf\n",
    "  term_document_matrix = term_document_matrix / LA.norm(term_document_matrix, axis=0)\n",
    "\n",
    "  return term_document_matrix\n",
    "\n",
    "def get_records_num_set(inverted_index_df):\n",
    "  inverted_index_df[\"RecordNum\"] = inverted_index_df[\"RecordNum\"].str.replace(\"'\", \"\")\n",
    "  inverted_index_df[\"RecordNum\"] = inverted_index_df[\"RecordNum\"].str.replace(\" \", \"\")\n",
    "  records_num = set([record_num for word in inverted_index_df[\"RecordNum\"].str[1:-1].str.split(\",\").tolist() for record_num in word])\n",
    "\n",
    "  return records_num\n",
    "\n",
    "print(\"Reading config files...\")\n",
    "config_dict = read_config_file(config_file)\n",
    "inverted_index_file = config_dict[\"leia\"]\n",
    "term_document_matrix_file = config_dict[\"escreva\"]\n",
    "\n",
    "print(\"Reading inverted index file...\")\n",
    "inverted_index_df = pd.read_csv(inverted_index_file, sep=';')\n",
    "\n",
    "records_num = get_records_num_set(inverted_index_df)\n",
    "words = inverted_index_df[\"Word\"].tolist()\n",
    "print(f\"Inverted index dimensions: ({len(words)},{len(records_num)}).\")\n",
    "\n",
    "print(\"Computing terms-documents matrix from inverted index...\")\n",
    "term_document_matrix = compute_term_document_matrix(inverted_index_df, records_num)\n",
    "\n",
    "print(\"Creating terms-documents matrix file...\")\n",
    "term_document_df = pd.DataFrame(data=term_document_matrix, index=words, columns=records_num)\n",
    "# term_document_df.to_csv(term_document_matrix_file, sep=\";\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>RecordNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WE</td>\n",
       "      <td>[00001,00002,00003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARE</td>\n",
       "      <td>[00001,00002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>[00001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BECOMING</td>\n",
       "      <td>[00002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BETTER</td>\n",
       "      <td>[00002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WILL</td>\n",
       "      <td>[00003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BE</td>\n",
       "      <td>[00003]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GREAT</td>\n",
       "      <td>[00003]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word            RecordNum\n",
       "0        WE  [00001,00002,00003]\n",
       "1       ARE        [00001,00002]\n",
       "2      GOOD              [00001]\n",
       "3  BECOMING              [00002]\n",
       "4    BETTER              [00002]\n",
       "5      WILL              [00003]\n",
       "6        BE              [00003]\n",
       "7     GREAT              [00003]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'are', 'good', 'becom', 'better', 'will', 'be', 'great']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import *\n",
    "ps = PorterStemmer()\n",
    "\n",
    "[ps.stem(term) for term in term_document_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "words = term_document_df.index.values\n",
    "my_array = np.zeros(8)\n",
    "print(my_array)\n",
    "word_index = np.flatnonzero(words == \"BEAUTIFUL\")\n",
    "my_array[word_index] = 1\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config files...\n",
      "Reading model and queries files...\n",
      "terms-documents matrix has the following dimensions: (8,3).\n",
      "There are 3 queries.\n",
      "Computing queries docs scores...\n",
      "Saving queries results...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryNumber</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 00001, 0.688207721799424]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 00002, 0.5584158923474207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2, 00003, 0.22821485436677302]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 00002, 0.5844829010200651]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 00003, 0.546454011634009]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryNumber                          Results\n",
       "0            1    [0, 00001, 0.688207721799424]\n",
       "1            1   [1, 00002, 0.5584158923474207]\n",
       "2            1  [2, 00003, 0.22821485436677302]\n",
       "3            2   [0, 00002, 0.5844829010200651]\n",
       "4            3    [0, 00003, 0.546454011634009]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute_queries_on_index(config_file):\n",
    "  print(\"Reading config files...\")\n",
    "  config_dict = read_config_file(config_file)\n",
    "  term_document_matrix_file = config_dict[\"modelo\"]\n",
    "  queries_file = config_dict[\"consultas\"]\n",
    "  queries_results_file = config_dict[\"resultados\"]\n",
    "\n",
    "  print(\"Reading model and queries files...\")\n",
    "  term_document_matrix_df = pd.read_csv(term_document_matrix_file, sep=';', index_col=0)\n",
    "  print(f\"terms-documents matrix has the following dimensions: ({len(term_document_matrix_df)},{len(term_document_matrix_df.columns)}).\")\n",
    "  queries_df = pd.read_csv(queries_file, sep=';', index_col=0)\n",
    "  print(f\"There are {len(queries_df)} queries.\")\n",
    "\n",
    "  print(\"Computing queries docs scores...\")\n",
    "  queries_scored_results_data= get_queries_scored_results_data(term_document_matrix_df, queries_df)\n",
    "  print(\"Saving queries results...\")\n",
    "  queries_scored_results_df = pd.DataFrame(data=queries_scored_results_data, columns=[\"QueryNumber\", \"Results\"])\n",
    "  return queries_scored_results_df\n",
    "  # queries_scored_results_df.to_csv(queries_results_file, sep=\";\", index=False)\n",
    "\n",
    "  print(\"Done!\")\n",
    "\n",
    "def get_queries_scored_results_data(term_document_matrix_df, queries_df):\n",
    "  def get_queries_vectors(query_text):\n",
    "    number_of_words = len(term_document_matrix_df.index)\n",
    "    query_vector = np.zeros(number_of_words)\n",
    "\n",
    "    for word in re.findall(r'\\w+', query_text):\n",
    "      word_index = np.flatnonzero(term_document_matrix_df.index == word)\n",
    "      query_vector[word_index] = 1\n",
    "\n",
    "    query_vector = query_vector / LA.norm(query_vector)\n",
    "\n",
    "    return query_vector\n",
    "\n",
    "  queries_vectors = queries_df[\"QueryText\"].apply(get_queries_vectors)\n",
    "\n",
    "  queries_scored_results_data = []\n",
    "  term_document_matrix = term_document_matrix_df.values\n",
    "  queries_vectors = queries_vectors.tolist()\n",
    "  # vectors are normalized, so dot product is the same as cosine similarity\n",
    "  queries_documents_similarities = np.dot(queries_vectors, term_document_matrix)\n",
    "\n",
    "  for i, query_documents_similarities in enumerate(queries_documents_similarities):\n",
    "    query_number = queries_df.index.values[i]\n",
    "    query_results = []\n",
    "\n",
    "    for j, query_document_similarity in enumerate(query_documents_similarities):\n",
    "      if query_document_similarity > 0:\n",
    "        document_number = term_document_matrix_df.columns[j]\n",
    "        query_results.append((document_number, query_document_similarity))\n",
    "\n",
    "    query_results = sorted(query_results, key=lambda tup: tup[1], reverse=True)\n",
    "    for j, query_result in enumerate(query_results):\n",
    "      queries_scored_results_data.append([query_number, [j, *query_result]])\n",
    "\n",
    "  return queries_scored_results_data\n",
    "\n",
    "queries_scored_results_df = execute_queries_on_index(\"../config/busca.cfg\")\n",
    "queries_scored_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index_file = \"../results/inverted_index.csv\"\n",
    "inverted_index_df = pd.read_csv(inverted_index_file, sep=';', na_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word                                                        NA\n",
       "RecordNum    ['00106 ', '00106 ', '00106 ', '00106 ', '0012...\n",
       "Name: 2658, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index_df.iloc[2658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
